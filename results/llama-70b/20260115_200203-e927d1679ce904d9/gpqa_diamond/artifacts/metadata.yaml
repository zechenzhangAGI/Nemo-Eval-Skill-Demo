launcher_resolved_config:
  deployment:
    type: none
  evaluation:
    nemo_evaluator_config:
      config:
        params:
          log_samples: true
          max_new_tokens: 2048
          parallelism: 4
          temperature: 0.6
    tasks:
    - env_vars:
        HF_TOKEN: HF_TOKEN
      name: gpqa_diamond
  execution:
    extra_docker_args: ''
    mode: sequential
    output_dir: ./results/llama-70b
    type: local
  target:
    api_endpoint:
      api_key_name: NGC_API_KEY
      model_id: meta/llama-3.1-70b-instruct
      url: https://integrate.api.nvidia.com/v1/chat/completions
versioning:
  nemo_evaluator_launcher: 0.1.67
  nemo_evaluator: 0.1.39
