# GPQA Diamond evaluation config for Llama 3.1 405B Instruct
defaults:
  - execution: local
  - deployment: none
  - _self_

execution:
  output_dir: ./results/llama-405b

target:
  api_endpoint:
    model_id: meta/llama-3.1-405b-instruct
    url: https://integrate.api.nvidia.com/v1/chat/completions
    api_key_name: NGC_API_KEY

evaluation:
  nemo_evaluator_config:
    config:
      params:
        temperature: 0.6
        max_new_tokens: 2048
        parallelism: 3
        log_samples: true
  tasks:
    - name: gpqa_diamond
      env_vars:
        HF_TOKEN: HF_TOKEN
